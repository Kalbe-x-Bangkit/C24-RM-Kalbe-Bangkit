{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas pillow tqdm datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure_path,Caption,Question,Choice A,Choice B,Choice C,Choice D,Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def load_image(image_name, image_folder):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            return img.copy()  # Copy the image object to avoid closing\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "def create_dataset(csv_file, image_folder, batch_size=1000, max_workers=4):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    total_rows = len(df)\n",
    "    dataset = []\n",
    "    error_log = []\n",
    "\n",
    "    for start_idx in range(0, total_rows, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_rows)\n",
    "        batch_df = df[start_idx:end_idx]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_row = {executor.submit(load_image, row['Figure_path'], image_folder): row for _, row in batch_df.iterrows()}\n",
    "            \n",
    "            for future in tqdm(as_completed(future_to_row), total=len(future_to_row), desc=f\"Processing batch {start_idx // batch_size + 1}\"):\n",
    "                row = future_to_row[future]\n",
    "                try:\n",
    "                    image = future.result()\n",
    "                    if isinstance(image, tuple):  # Checking if an error occurred\n",
    "                        error_log.append((row['Figure_path'], image[1]))\n",
    "                    else:\n",
    "                        dataset.append({\n",
    "                            \"image\": image,\n",
    "                            \"caption\": row['Caption'],\n",
    "                            \"question\": row['Question'],\n",
    "                            \"choice a\": row['Choice A'],\n",
    "                            \"choice b\": row['Choice B'],\n",
    "                            \"choice c\": row['Choice C'],\n",
    "                            \"choice d\": row['Choice D'],\n",
    "                            \"answer\": row['Answer'] \n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    error_log.append((row['Figure_path'], str(e)))\n",
    "\n",
    "    # Save error log to a file\n",
    "    with open('error_log.txt', 'w') as f:\n",
    "        for error in error_log:\n",
    "            f.write(f\"{error[0]}: {error[1]}\\n\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 1: 100%|██████████| 1000/1000 [00:00<00:00, 1091.38it/s]\n",
      "Processing batch 2: 100%|██████████| 1000/1000 [00:00<00:00, 1341.53it/s]\n",
      "Processing batch 3: 100%|██████████| 1000/1000 [00:00<00:00, 1151.59it/s]\n",
      "Processing batch 4: 100%|██████████| 1000/1000 [00:00<00:00, 1254.08it/s]\n",
      "Processing batch 5: 100%|██████████| 1000/1000 [00:00<00:00, 1029.32it/s]\n",
      "Processing batch 6: 100%|██████████| 1000/1000 [00:01<00:00, 964.77it/s] \n",
      "Processing batch 7: 100%|██████████| 1000/1000 [00:00<00:00, 1191.94it/s]\n",
      "Processing batch 8: 100%|██████████| 1000/1000 [00:00<00:00, 1058.89it/s]\n",
      "Processing batch 9: 100%|██████████| 1000/1000 [00:00<00:00, 1100.48it/s]\n",
      "Processing batch 10: 100%|██████████| 1000/1000 [00:01<00:00, 929.41it/s]\n",
      "Processing batch 11: 100%|██████████| 1000/1000 [00:01<00:00, 973.58it/s]\n",
      "Processing batch 12: 100%|██████████| 1000/1000 [00:01<00:00, 931.44it/s]\n",
      "Processing batch 13: 100%|██████████| 1000/1000 [00:01<00:00, 844.90it/s]\n",
      "Processing batch 14: 100%|██████████| 1000/1000 [00:01<00:00, 907.24it/s]\n",
      "Processing batch 15: 100%|██████████| 1000/1000 [00:01<00:00, 778.97it/s]\n",
      "Processing batch 16: 100%|██████████| 1000/1000 [00:01<00:00, 911.15it/s]\n",
      "Processing batch 17: 100%|██████████| 1000/1000 [00:01<00:00, 817.62it/s]\n",
      "Processing batch 18: 100%|██████████| 1000/1000 [00:01<00:00, 770.19it/s]\n",
      "Processing batch 19: 100%|██████████| 1000/1000 [00:01<00:00, 756.64it/s]\n",
      "Processing batch 20: 100%|██████████| 1000/1000 [00:01<00:00, 719.90it/s]\n",
      "Processing batch 21: 100%|██████████| 1000/1000 [00:01<00:00, 730.87it/s]\n",
      "Processing batch 22: 100%|██████████| 1000/1000 [00:01<00:00, 708.10it/s]\n",
      "Processing batch 23: 100%|██████████| 1000/1000 [00:01<00:00, 645.51it/s]\n",
      "Processing batch 24: 100%|██████████| 1000/1000 [00:01<00:00, 507.44it/s]\n",
      "Processing batch 25: 100%|██████████| 1000/1000 [00:01<00:00, 521.52it/s]\n",
      "Processing batch 26: 100%|██████████| 1000/1000 [00:01<00:00, 536.51it/s]\n",
      "Processing batch 27: 100%|██████████| 1000/1000 [00:01<00:00, 508.99it/s]\n",
      "Processing batch 28: 100%|██████████| 1000/1000 [00:02<00:00, 496.55it/s]\n",
      "Processing batch 29: 100%|██████████| 1000/1000 [00:01<00:00, 547.87it/s]\n",
      "Processing batch 30: 100%|██████████| 1000/1000 [00:02<00:00, 467.61it/s]\n",
      "Processing batch 31: 100%|██████████| 1000/1000 [00:02<00:00, 452.00it/s]\n",
      "Processing batch 32: 100%|██████████| 1000/1000 [00:02<00:00, 364.16it/s]\n",
      "Processing batch 33: 100%|██████████| 1000/1000 [00:02<00:00, 460.06it/s]\n",
      "Processing batch 34: 100%|██████████| 430/430 [00:00<00:00, 443.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "csv_file = 'test_2.csv'\n",
    "image_folder = 'images_2'\n",
    "test_dataset = create_dataset(csv_file, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "def load_image(image_name, image_folder):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            return img.copy(), None  # Return image and no error\n",
    "    except Exception as e:\n",
    "        return None, str(e)  # Return None and the error message\n",
    "\n",
    "def process_batch(batch_df, image_folder):\n",
    "    batch_data = []\n",
    "    error_log = []\n",
    "\n",
    "    for _, row in batch_df.iterrows():\n",
    "        image_name = row['Figure_path']\n",
    "        caption = row['Caption']\n",
    "        question = row['Question']\n",
    "        answer = row['Answer']\n",
    "        choice_a = row['Choice A']\n",
    "        choice_b = row['Choice B']\n",
    "        choice_c = row['Choice C']\n",
    "        choice_d = row['Choice D']\n",
    "\n",
    "        image, error = load_image(image_name, image_folder)\n",
    "        if error:\n",
    "            error_log.append((image_name, error))\n",
    "        else:\n",
    "            batch_data.append({\n",
    "                \"image\": image,\n",
    "                \"caption\": caption,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"choice a\": choice_a,\n",
    "                \"choice b\": choice_b,\n",
    "                \"choice c\": choice_c,\n",
    "                \"choice d\":choice_d\n",
    "            })\n",
    "\n",
    "    return batch_data, error_log\n",
    "\n",
    "def create_and_save_batches(csv_file, image_folder, batch_size=1000, output_dir='output_batches'):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    total_rows = len(df)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    all_error_logs = []\n",
    "\n",
    "    for start_idx in range(0, total_rows, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_rows)\n",
    "        batch_df = df[start_idx:end_idx]\n",
    "        \n",
    "        batch_data, error_log = process_batch(batch_df, image_folder)\n",
    "        all_error_logs.extend(error_log)\n",
    "\n",
    "        # Convert batch_data to Dataset and save\n",
    "        if batch_data:\n",
    "            data_dict = {\n",
    "                'image': [data['image'] for data in batch_data],\n",
    "                'caption': [data['caption'] for data in batch_data],\n",
    "                'question': [data['question'] for data in batch_data],\n",
    "                'answer': [data['answer'] for data in batch_data],\n",
    "                'choice a': [data['choice a'] for data in batch_data],\n",
    "                'choice b': [data['choice b'] for data in batch_data],\n",
    "                'choice c': [data['choice c'] for data in batch_data],\n",
    "                'choice d': [data['choice d'] for data in batch_data]\n",
    "\n",
    "            }\n",
    "            batch_dataset = Dataset.from_dict(data_dict)\n",
    "            batch_dataset.save_to_disk(os.path.join(output_dir, f'batch_{start_idx // batch_size}'))\n",
    "\n",
    "    # Save error log to a file\n",
    "    with open(os.path.join(output_dir, 'error_log.txt'), 'w') as f:\n",
    "        for error in all_error_logs:\n",
    "            f.write(f\"{error[0]}: {error[1]}\\n\")\n",
    "\n",
    "def load_combined_dataset(output_dir='output_batches'):\n",
    "    batches = [os.path.join(output_dir, d) for d in os.listdir(output_dir) if d.startswith('batch_')]\n",
    "    datasets = [load_from_disk(batch) for batch in batches]\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 2233.60 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 5208.85 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\PIL\\ImageFile.py:536\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[0;32m    537\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages_2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/hp pav/Downloads/PMC-VQA2/batch\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mcreate_and_save_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 74\u001b[0m, in \u001b[0;36mcreate_and_save_batches\u001b[1;34m(csv_file, image_folder, batch_size, output_dir)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_data:\n\u001b[0;32m     63\u001b[0m         data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch_data],\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m: [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch_data],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \n\u001b[0;32m     73\u001b[0m         }\n\u001b[1;32m---> 74\u001b[0m         batch_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m         batch_dataset\u001b[38;5;241m.\u001b[39msave_to_disk(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Save error log to a file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:963\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[1;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[0;32m    961\u001b[0m     arrow_typed_mapping[col] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    962\u001b[0m mapping \u001b[38;5;241m=\u001b[39m arrow_typed_mapping\n\u001b[1;32m--> 963\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\datasets\\table.py:758\u001b[0m, in \u001b[0;36mInMemoryTable.from_pydict\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pydict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    744\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;124;03m    Construct a Table from Arrow arrays or columns.\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03m        `datasets.table.Table`\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\pyarrow\\table.pxi:1920\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular.from_pydict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\pyarrow\\table.pxi:5992\u001b[0m, in \u001b[0;36mpyarrow.lib._from_pydict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\pyarrow\\array.pxi:385\u001b[0m, in \u001b[0;36mpyarrow.lib.asarray\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\pyarrow\\array.pxi:247\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\pyarrow\\array.pxi:112\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\datasets\\arrow_writer.py:170\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# automatic type inference for custom objects\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtry_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_custom_type_and_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtry_type \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrying_type \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\datasets\\arrow_writer.py:158\u001b[0m, in \u001b[0;36mTypedSequence._infer_custom_type_and_encode\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    156\u001b[0m     non_null_idx, non_null_value \u001b[38;5;241m=\u001b[39m first_non_null_value(data)\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(non_null_value, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m data], Image()\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\datasets\\features\\image.py:121\u001b[0m, in \u001b[0;36mImage.encode_example\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encode_np_array(value)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# convert the PIL image to bytes (default format is PNG/TIFF)\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_pil_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# we set \"bytes\": None to not duplicate the data if they're already available locally\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\datasets\\features\\image.py:315\u001b[0m, in \u001b[0;36mencode_pil_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: image\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mimage_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m}\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\datasets\\features\\image.py:307\u001b[0m, in \u001b[0;36mimage_to_bytes\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPNG\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTIFF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 307\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\PIL\\Image.py:2459\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2456\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2458\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2459\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1412\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1408\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[0;32m   1409\u001b[0m         im, fp, chunk, rawmode, default_image, append_images\n\u001b[0;32m   1410\u001b[0m     )\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[1;32m-> 1412\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\PIL\\ImageFile.py:540\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    538\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 540\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    542\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\PIL\\ImageFile.py:559\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 559\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    560\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "csv_file = 'train_2.csv'\n",
    "image_folder = 'images_2'\n",
    "output_dir = 'C:/Users/hp pav/Downloads/PMC-VQA2/batch'\n",
    "create_and_save_batches(csv_file, image_folder, batch_size=1000, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_from_disk, concatenate_datasets\n",
    "\n",
    "def load_combined_dataset(output_dir='output_batches'):\n",
    "    batches = [os.path.join(output_dir, d) for d in os.listdir(output_dir) if d.startswith('batch_')]\n",
    "    datasets = [load_from_disk(batch) for batch in batches]\n",
    "    combined_dataset = concatenate_datasets(datasets)\n",
    "    return DatasetDict({'train': combined_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load combined dataset\n",
    "output_dir = 'C:/Users/hp pav/Downloads/PMC-VQA2/batch'\n",
    "train_dataset = load_combined_dataset(output_dir)\n",
    "# print(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'caption', 'question', 'answer', 'choice a', 'choice b', 'choice c', 'choice d'],\n",
       "        num_rows: 152603\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = train_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'caption', 'question', 'answer', 'choice a', 'choice b', 'choice c', 'choice d'],\n",
       "    num_rows: 152603\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'caption', 'question', 'answer', 'choice a', 'choice b', 'choice c', 'choice d'],\n",
       "    num_rows: 152603\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 3648.92 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4078.42 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 3685.05 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 3991.17 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 3695.51 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4852.14 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4628.02 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4468.60 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 5909.48 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4437.49 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4510.70 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4177.72 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4391.31 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 5054.19 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4473.01 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 5459.68 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4994.64 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4929.18 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4988.02 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4383.37 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4305.98 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4507.02 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4107.85 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4846.38 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4027.45 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4364.01 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4808.74 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4656.67 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4802.08 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4092.83 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4041.85 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4173.33 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 4703.36 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 430/430 [00:00<00:00, 4360.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "csv_file = 'test_2.csv'\n",
    "image_folder = 'images_2'\n",
    "output_dir = 'C:/Users/hp pav/Downloads/PMC-VQA2/test_batch'\n",
    "create_and_save_batches(csv_file, image_folder, batch_size=1000, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load combined dataset\n",
    "output_dir = 'C:/Users/hp pav/Downloads/PMC-VQA2/test_batch'\n",
    "test_dataset = load_combined_dataset(output_dir)\n",
    "# print(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'caption', 'question', 'answer', 'choice a', 'choice b', 'choice c', 'choice d'],\n",
       "    num_rows: 33430\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict = test_dataset['train']\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "csv_file = 'train_2.csv'\n",
    "image_folder = 'images_2'\n",
    "train_dataset = create_dataset(csv_file, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "def convert_to_datasetdict(dataset_list):\n",
    "    # Convert list of dictionaries to a format suitable for Dataset\n",
    "    images = [data['image'] for data in dataset_list]\n",
    "    captions = [data['caption'] for data in dataset_list]\n",
    "    questions = [data['question'] for data in dataset_list]\n",
    "    answers = [data['answer'] for data in dataset_list]\n",
    "    choice_a = [data['choice a'] for data in dataset_list]\n",
    "    choice_b = [data['choice b'] for data in dataset_list]\n",
    "    choice_c = [data['choice c'] for data in dataset_list]\n",
    "    choice_d = [data['choice d'] for data in dataset_list]\n",
    "\n",
    "    # Create a dictionary suitable for Dataset.from_dict\n",
    "    data_dict = {\n",
    "        'image': images,\n",
    "        'caption': captions,\n",
    "        'question': questions,\n",
    "        'answer': answers,\n",
    "        'choice a': choice_a,\n",
    "        'choice b': choice_b,\n",
    "        'choice c': choice_c,\n",
    "        'choice d': choice_d\n",
    "    }\n",
    "\n",
    "    # Create a Dataset from the dictionary\n",
    "    dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "def convert_to_datasetdict(dataset_list):\n",
    "    # Initialize lists to store data\n",
    "    images, captions, questions, answers = [], [], [], []\n",
    "    choice_a, choice_b, choice_c, choice_d = [], [], [], []\n",
    "\n",
    "    # Iterate over dataset_list with progress bar\n",
    "    for data in tqdm(dataset_list, desc=\"Converting to DatasetDict\"):\n",
    "        images.append(data['image'])\n",
    "        captions.append(data['caption'])\n",
    "        questions.append(data['question'])\n",
    "        answers.append(data['answer'])\n",
    "        choice_a.append(data['choice a'])\n",
    "        choice_b.append(data['choice b'])\n",
    "        choice_c.append(data['choice c'])\n",
    "        choice_d.append(data['choice d'])\n",
    "\n",
    "    # Create a dictionary suitable for Dataset.from_dict\n",
    "    data_dict = {\n",
    "        'image': images,\n",
    "        'caption': captions,\n",
    "        'question': questions,\n",
    "        'answer': answers,\n",
    "        'choice a': choice_a,\n",
    "        'choice b': choice_b,\n",
    "        'choice c': choice_c,\n",
    "        'choice d': choice_d\n",
    "    }\n",
    "\n",
    "    # Create a Dataset from the dictionary\n",
    "    dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_to_datasetdict(dataset_list):\n",
    "    # Initialize lists to store data\n",
    "    images, captions, questions, answers = [], [], [], []\n",
    "    choice_a, choice_b, choice_c, choice_d = [], [], [], []\n",
    "\n",
    "    # Iterate over dataset_list with progress bar\n",
    "    for data in tqdm(dataset_list, desc=\"Converting to DatasetDict\", total=len(dataset_list)):\n",
    "        images.append(data['image'])\n",
    "        captions.append(data['caption'])\n",
    "        questions.append(data['question'])\n",
    "        answers.append(data['answer'])\n",
    "        choice_a.append(data['choice a'])\n",
    "        choice_b.append(data['choice b'])\n",
    "        choice_c.append(data['choice c'])\n",
    "        choice_d.append(data['choice d'])\n",
    "\n",
    "    # Create a dictionary suitable for Dataset.from_dict\n",
    "    data_dict = {\n",
    "        'image': images,\n",
    "        'caption': captions,\n",
    "        'question': questions,\n",
    "        'answer': answers,\n",
    "        'choice a': choice_a,\n",
    "        'choice b': choice_b,\n",
    "        'choice c': choice_c,\n",
    "        'choice d': choice_d\n",
    "    }\n",
    "\n",
    "    # Create a Dataset from the dictionary\n",
    "    dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to DatasetDict:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_datasetdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m, in \u001b[0;36mconvert_to_datasetdict\u001b[1;34m(dataset_list)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Iterate over dataset_list with progress bar\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting to DatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset_list)):\n\u001b[1;32m---> 11\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     12\u001b[0m     captions\u001b[38;5;241m.\u001b[39mappend(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m     questions\u001b[38;5;241m.\u001b[39mappend(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "test_dict = convert_to_datasetdict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = convert_to_datasetdict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    \"train\": newtrain_dict,\n",
    "    \"test\": newtest_dict,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'caption', 'question', 'answer', 'choice a', 'choice b', 'choice c', 'choice d', 'answer label'],\n",
       "        num_rows: 152603\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'caption', 'question', 'answer', 'choice a', 'choice b', 'choice c', 'choice d', 'answer label'],\n",
       "        num_rows: 33430\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=341x247>,\n",
       " 'caption': 'A slightly altered cell . (c-c‴) A highly altered cell as seen from 4 different angles . Note mitochondria/mitochondrial networks (green), Golgi complexes (red), cell nuclei (light blue) and the cell outline (yellow).',\n",
       " 'question': ' What color is used to label the Golgi complexes in the image?',\n",
       " 'answer': 'Red',\n",
       " 'choice a': ' A: Green ',\n",
       " 'choice b': ' B: Red ',\n",
       " 'choice c': ' C: Light blue ',\n",
       " 'choice d': ' D: Yellow',\n",
       " 'answer label': 'B'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56d118b16e247bababb10ae9e062e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f4f14bf8334f69af3f3ccb907938b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be988c3e7edb4cdfa8b4bf9c996eda27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e662342d7b3947e58e006db0c82cd4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd85596bc6843ffab2b3fe04ff34745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ff58fa6c0c4ec98e8fc3cc962e3ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a166d659352741de9ca783d1bb470a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d0896164e6442aa070d3ad155afbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87036213b074688b210f8dd9dc09f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ba2eb33f1c4e6babc4c22caed09dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eca3a4949b14a1c8e78b627d4d2bb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3e7bf744e54d23926707ede1e0373c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa750c908e748a996b1af1669bec71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270519d7abc847a9b1ca2e4ffba5651d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf56ddd1af5a4fbaaadf8f8cc4827100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50729c1ffcb747f5a7c1f6cc6e90916b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c592f934a1de41e0aca1c17a33ef056b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c05a37e659444fdaea35ad02476d025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6501f950fc4b9d886a8eea82d511e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5870 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be045768f3ba4d8bbdf1dd1571ec8032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a040c44812b438eb25055257bef3e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b51a4383ee4b7e89db937cdc0ada00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b9bb0614b54e0ab755573d90d7068a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e44bece582417a8be1d4bcd8853d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9914f5cb424c138e4806a32c105ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1047003fa6174923955943a1d747c369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716b5578e7b24d2393dcd34451ccce90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bded597ece0442aa8e78ce0a249724ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ea96d8d0194cd4815635f5647b7303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109befb095ca4a2b9cf7855b709596d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a7ca5c253c4d21b9501213de52073d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccc0fc5b09e4bb89b941185e114a038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc287d543c949e3acc4bdd91029acfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1af83d2ac014a4e8aceeee703d5bc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe25595ddbbd421caa2add954b2a4d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16529f8091c64c1a915621b1726c4ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a32fa0069e42ecb61bacaff1e074df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52f97f554a040e191015d4b937e600e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012c2338cb64496a85c6fd381215fab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cfe025277544b380a3f661b901da95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c47e4e5b6e94989ae094eab4d1b7a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb01bfc0078748448654aadd7d45d5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b15b3d5c9fd4686a30e308324be2093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c32d02f9fa49efad9956308d438646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e626c6490cd04222a84392e724996b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59975b5552a44f6c90aa6a6334fff9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbd0bb505c44255ada956a99be56dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e4c6a1c0454ffb8cd751125a82d842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cdfaa60ecf46c085fee2445c45c119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62cb5c072c14d5d8c97fc5d1695b931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad99f70d3b349bbb27d46c1ab5e9c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dbfc651a7b41ff83260e9bf11f0032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0346e372264e18b9e4e578f2f1fec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d479393978d34837b3ae664fdbf21720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32df98367e64d56b75059f9334b460b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4a5ad4851a4a7997d6363e0a26a9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc13e1a060b42038583106e521a9a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3dce8f1cb84789b27e125567521cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c15e0491d74412c9105813f560943f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dd168124cd4b96ad896be3fe547a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3993765d2f843999ea892e09b8430fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f7b1e3ff7440b8832ba1fe30a79d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed68d8c574d4c21937c044f18e3be79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518a76f354b74c298bbbe58e6d549250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d11cba3afc4f948fa253f22e29841c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6689e3a3344fb8abbd613773c3e6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151f54cfc9884048968d43bb1dd08156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8060da268f40308b078a6c16cc8dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b551c13d58421fba6bfd015a066ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd2f38a07ab4aa7be403c061ad1b1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/658 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp pav\\Downloads\\PMC-VQA2\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp pav\\.cache\\huggingface\\hub\\datasets--mdwiratathya--PMC-VQA_small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mdwiratathya/PMC-VQA_small/commit/e41ce0b311397b8c1bfe85c80048d9e0c0adcdfe', commit_message='minor editing', commit_description='adding answer label and change then answer to not only contains alphabet', oid='e41ce0b311397b8c1bfe85c80048d9e0c0adcdfe', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"mdwiratathya/PMC-VQA_small\", commit_message=\"minor editing\", commit_description=\"adding answer label and change then answer to not only contains alphabet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def transform_row(row):\n",
    "    # Move the answer to answer_label\n",
    "    row['answer label'] = row['answer']\n",
    "    \n",
    "    # Determine the full answer based on the answer label and update the answer field without the alphabet prefix\n",
    "    if row['answer'] == 'A':\n",
    "        row['answer'] = row['choice a'][3:].strip()  # Remove 'A: ' prefix\n",
    "    elif row['answer'] == 'B':\n",
    "        row['answer'] = row['choice b'][3:].strip()  # Remove 'B: ' prefix\n",
    "    elif row['answer'] == 'C':\n",
    "        row['answer'] = row['choice c'][3:].strip()  # Remove 'C: ' prefix\n",
    "    elif row['answer'] == 'D':\n",
    "        row['answer'] = row['choice d'][3:].strip()  # Remove 'D: ' prefix\n",
    "    \n",
    "    return row\n",
    "\n",
    "def convert_to_datasetdict(dataset):\n",
    "    # Apply the transformation to the dataset\n",
    "    transformed_dataset = dataset.map(transform_row, desc=\"Converting to DatasetDict\")\n",
    "    return transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=346x292>,\n",
       " 'caption': 'CT pulmonary angiogram reveals encasement and displacement of the left anterior descending coronary artery ( blue arrows ).',\n",
       " 'question': ' What is the name of the artery encased and displaced in the image? ',\n",
       " 'answer': 'B',\n",
       " 'choice a': ' A: Right Coronary Artery ',\n",
       " 'choice b': ' B: Left Anterior Descending Coronary Artery ',\n",
       " 'choice c': ' C: Circumflex Coronary Artery ',\n",
       " 'choice d': ' D: Superior Mesenteric Artery '}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtest_dict = convert_to_datasetdict(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'caption', 'question', 'answer', 'choice a', 'choice b', 'choice c', 'choice d', 'answer label'],\n",
       "    num_rows: 33430\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtest_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=646x390>,\n",
       " 'caption': 'showing enlarged parotid glands with multi-loculated cystic formations, the septa are of intermediate signal enhancing after gadulinium injection.',\n",
       " 'question': ' What type of imaging was used to visualize the parotid glands? ',\n",
       " 'answer': 'MRI scan',\n",
       " 'choice a': ' A: CT scan ',\n",
       " 'choice b': ' B: MRI scan ',\n",
       " 'choice c': ' C: X-ray ',\n",
       " 'choice d': ' D: Ultrasound scan  ',\n",
       " 'answer label': 'B'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtest_dict[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain_dict = convert_to_datasetdict(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=360x217>,\n",
       " 'caption': 'MR of brain (diffusion weighted image) demonstrating multiterritory acute infarct ; b Time of flight MR demonstrating bilateral ICA occlusion ; and c DSA demonstrating anterior circulation supplied by posterior circulation.',\n",
       " 'question': ' What does the DSA image demonstrate?',\n",
       " 'answer': 'Anterior circulation supplied by posterior circulation',\n",
       " 'choice a': ' A: Acute infarct ',\n",
       " 'choice b': ' B: Bilateral ICA occlusion ',\n",
       " 'choice c': ' C: Anterior circulation supplied by posterior circulation ',\n",
       " 'choice d': ' D: None of the above ',\n",
       " 'answer label': 'C'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtrain_dict[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
